{
  "verdict": "CHANGES_REQUIRED",
  "summary": "Found a division-by-zero bug when windowHours is 0 or negative; added safe normalization to prevent runtime errors and invalid SQL intervals.",
  "issues": [
    {
      "severity": "critical",
      "file": "packages/services/velocity-service.ts",
      "line": 68,
      "description": "Division by zero can occur if windowHours is 0n or negative. This can also create an invalid SQL interval in fetchHourlyBuckets. windowHours is user-provided and not validated.",
      "current_code": "```typescript\nexport async function computeSnapshot(\n  pool: Pool,\n  communityId: string,\n  windowHours: bigint = DEFAULT_WINDOW_HOURS,\n): Promise<VelocitySnapshot> {\n  if (!isFeatureEnabled('FEATURE_VELOCITY_ALERTS')) {\n    return createEmptySnapshot(communityId, windowHours);\n  }\n\n  return withCommunityScope(communityId, pool, async (client) => {\n    // Step 1: Fetch hourly buckets from rollup table (AC-3.3.1)\n    const buckets = await fetchHourlyBuckets(client, communityId, windowHours);\n    const bucketCount = BigInt(buckets.length);\n\n    // Step 2: Compute velocity (total spend / window hours) — BigInt only\n    const totalSpend = buckets.reduce(\n      (sum, b) => sum + b.totalMicro,\n      0n,\n    );\n    const velocityMicroPerHour = bucketCount > 0n\n      ? totalSpend / windowHours\n      : 0n;\n\n    // Step 3: Compute acceleration from half-window comparison (AC-3.3.4)\n    const accelerationMicroPerHour2 = computeAcceleration(\n      buckets,\n      windowHours,\n    );\n\n    // Step 4: Get available balance (AC-3.3.3, IMP-010)\n    const availableBalanceMicro = await getAvailableBalance(\n      client,\n      communityId,\n    );\n\n    // Step 5: Compute exhaustion prediction\n    const estimatedExhaustionHours = computeExhaustion(\n      availableBalanceMicro,\n      velocityMicroPerHour,\n    );\n\n    // Step 6: Confidence scoring (AC-3.3.5)\n    const confidence = scoreConfidence(bucketCount);\n\n    return {\n      communityId,\n      computedAt: new Date(),\n      windowHours,\n      velocityMicroPerHour,\n      accelerationMicroPerHour2,\n      availableBalanceMicro,\n      estimatedExhaustionHours,\n      confidence,\n      bucketCount,\n    };\n  });\n}\n```\n```typescript\nasync function fetchHourlyBuckets(\n  client: PoolClient,\n  communityId: string,\n  windowHours: bigint,\n): Promise<HourlyBucket[]> {\n  const result = await client.query<{\n    hour: Date;\n    total_micro: string;\n    entry_count: string;\n  }>(\n    `SELECT hour, total_micro, entry_count\n     FROM community_debit_hourly\n     WHERE community_id = $1\n       AND hour >= NOW() - ($2 || ' hours')::INTERVAL\n     ORDER BY hour ASC`,\n    [communityId, windowHours.toString()],\n  );\n\n  return result.rows.map((row) => ({\n    hour: row.hour,\n    totalMicro: BigInt(row.total_micro),\n    entryCount: BigInt(row.entry_count),\n  }));\n}\n```",
      "fixed_code": "```typescript\nexport async function computeSnapshot(\n  pool: Pool,\n  communityId: string,\n  windowHours: bigint = DEFAULT_WINDOW_HOURS,\n): Promise<VelocitySnapshot> {\n  const effectiveWindowHours = windowHours > 0n ? windowHours : DEFAULT_WINDOW_HOURS;\n\n  if (!isFeatureEnabled('FEATURE_VELOCITY_ALERTS')) {\n    return createEmptySnapshot(communityId, effectiveWindowHours);\n  }\n\n  return withCommunityScope(communityId, pool, async (client) => {\n    // Step 1: Fetch hourly buckets from rollup table (AC-3.3.1)\n    const buckets = await fetchHourlyBuckets(client, communityId, effectiveWindowHours);\n    const bucketCount = BigInt(buckets.length);\n\n    // Step 2: Compute velocity (total spend / window hours) — BigInt only\n    const totalSpend = buckets.reduce(\n      (sum, b) => sum + b.totalMicro,\n      0n,\n    );\n    const velocityMicroPerHour = bucketCount > 0n\n      ? totalSpend / effectiveWindowHours\n      : 0n;\n\n    // Step 3: Compute acceleration from half-window comparison (AC-3.3.4)\n    const accelerationMicroPerHour2 = computeAcceleration(\n      buckets,\n      effectiveWindowHours,\n    );\n\n    // Step 4: Get available balance (AC-3.3.3, IMP-010)\n    const availableBalanceMicro = await getAvailableBalance(\n      client,\n      communityId,\n    );\n\n    // Step 5: Compute exhaustion prediction\n    const estimatedExhaustionHours = computeExhaustion(\n      availableBalanceMicro,\n      velocityMicroPerHour,\n    );\n\n    // Step 6: Confidence scoring (AC-3.3.5)\n    const confidence = scoreConfidence(bucketCount);\n\n    return {\n      communityId,\n      computedAt: new Date(),\n      windowHours: effectiveWindowHours,\n      velocityMicroPerHour,\n      accelerationMicroPerHour2,\n      availableBalanceMicro,\n      estimatedExhaustionHours,\n      confidence,\n      bucketCount,\n    };\n  });\n}\n```\n```typescript\nasync function fetchHourlyBuckets(\n  client: PoolClient,\n  communityId: string,\n  windowHours: bigint,\n): Promise<HourlyBucket[]> {\n  const effectiveWindowHours = windowHours > 0n ? windowHours : DEFAULT_WINDOW_HOURS;\n\n  const result = await client.query<{\n    hour: Date;\n    total_micro: string;\n    entry_count: string;\n  }>(\n    `SELECT hour, total_micro, entry_count\n     FROM community_debit_hourly\n     WHERE community_id = $1\n       AND hour >= NOW() - ($2 || ' hours')::INTERVAL\n     ORDER BY hour ASC`,\n    [communityId, effectiveWindowHours.toString()],\n  );\n\n  return result.rows.map((row) => ({\n    hour: row.hour,\n    totalMicro: BigInt(row.total_micro),\n    entryCount: BigInt(row.entry_count),\n  }));\n}\n```",
      "explanation": "Normalizing windowHours to a positive BigInt prevents division by zero and invalid SQL intervals while keeping BigInt-only arithmetic. The rest of the computation now uses a safe value consistently."
    }
  ],
  "fabrication_check": {
    "passed": true,
    "concerns": []
  },
  "iteration": 1
}
