{
  "verdict": "CHANGES_REQUIRED",
  "summary": "As written, the PRD contains a few hard contradictions and underspecified/measurability gaps that could cause you to ship a “compliant-looking” set of docs/tests while either breaking production inputs or failing to actually enable shadow→enforce and provider-side contract enforcement.",
  "blocking_issues": [
    {
      "location": "FR-3 + NFR-3 (Schema validation) vs AC-3.1/AC-3.4",
      "issue": "Contradictory constraints: FR-3/AC-3.4 require the gateway schema to be equal-or-tighter than the boundary parser (never accept what boundary rejects), while NFR-3 requires not rejecting any inputs currently accepted in production. If production currently accepts any inputs that the boundary parser rejects (or accepts via legacy mode but would be rejected by canonical), an equal-or-tighter gateway will necessarily start rejecting them earlier, violating NFR-3.",
      "why_blocking": "This can force a choice between breaking existing clients (project failure for a platform) or weakening the schema (violating the stated safety property). Teams often discover late that “production-accepted” includes legacy quirks, whitespace, plus signs, leading zeros, empty strings, etc.",
      "fix": "Make the compatibility target explicit and mode-aware: define the exact acceptance language for (a) legacy, (b) canonical, and (c) current production behavior per route. Then choose one of: (1) Gateway schema matches *current production acceptance* during shadow, and tightens only when enforce is operationally enabled; or (2) Introduce a 3-mode gateway validator mirroring parseBoundaryMicroUsd (legacy/shadow/enforce) with metrics and a graduation plan. Update NFR-3 to reference the chosen mode."
    },
    {
      "location": "FR-1 (Graduation criteria) + NFR-4 (Observability) + AC-1.3",
      "issue": "Graduation criteria include “quarantine replay success rate: all quarantined inputs must be replayed successfully through the canonical parser after investigation,” but the PRD does not define what constitutes quarantine, where quarantined inputs are stored, how replay is executed, or how “after investigation” becomes a measurable, automatable threshold. AC-1.3 claims existing metrics are sufficient, but the required criterion is not computable from the listed counters alone.",
      "why_blocking": "You can’t build a readiness endpoint or enforceable graduation gates without a defined data source and a deterministic computation. This risks shipping a non-actionable readiness page and “criteria” that can never be evaluated, stalling shadow mode indefinitely (the exact failure mode the PRD is trying to prevent).",
      "fix": "Define the quarantine mechanism as part of FR-1: (a) what gets quarantined (e.g., inputs where legacy!=canonical or wouldReject), (b) retention/store (log sink, DB table, S3), (c) replay workflow (batch job/script + idempotency), and (d) a measurable threshold (e.g., ≥99.9% of quarantined items replayed within 7 days; 0 unresolved items older than 14 days). If you truly want “no new storage this cycle,” then change the criterion to something computable from existing metrics (e.g., divergence rate + wouldReject rate + sampled replay via logs) and explicitly drop “all quarantined inputs” language."
    },
    {
      "location": "FR-2 (Consumer-driven contract testing) acceptance criteria AC-2.1–AC-2.5",
      "issue": "The PRD calls this “Pact pattern” but defines a contract spec that includes internal/provider-specific details (e.g., “evaluator builtin count,” “conservation property count”) and “types, functions, and behaviors it depends on.” This is not a stable consumer-driven contract boundary and is likely to couple to hounfour internals, contradicting the stated mitigation (“Spec tests behaviors, not implementation details”).",
      "why_blocking": "If the contract is defined in terms of internal counts or non-semver-stable details, hounfour will either (a) refuse to adopt it, (b) constantly break CI for non-breaking refactors, or (c) game the contract without preserving real compatibility. Any of these defeats the core purpose: preventing breaking changes before release.",
      "fix": "Redefine the contract at the actual integration seam: exported API surface + semantic behaviors. Concretely: (1) pin the exact entrypoints used by freeside (module paths + function signatures), (2) include the conformance vectors as the behavioral contract (hash + versioned bundle), and (3) define provider verification as “run vectors and invariants,” not “builtin count.” If you need counts, make them explicitly informational/non-gating or tie them to a versioned capability flag."
    },
    {
      "location": "FR-1 AC-1.4 (/admin/boundary-readiness endpoint) + Security context (JWT boundary verification, RLS multi-tenancy)",
      "issue": "An admin readiness endpoint is introduced without any access-control requirement (authn/authz), tenancy scoping, or deployment exposure constraints. In a multi-tenant, token-gated platform, an unauthenticated or broadly accessible readiness endpoint can leak operational/security-sensitive data (divergence rates, reject rates, migration state) and become an attack surface.",
      "why_blocking": "Security regressions or data leakage are release blockers in practice. This is especially risky because the endpoint is new and “admin” paths are often accidentally exposed through gateways/ingress defaults.",
      "fix": "Add explicit requirements: endpoint must be protected (e.g., internal-only network policy + admin JWT claim check), must not be tenant-readable unless scoped, and must redact/aggregate metrics appropriately. Alternatively, make it a metrics-only signal (Prometheus gauge) rather than an HTTP endpoint."
    },
    {
      "location": "FR-4 (TTL-based invalidation option) + existing architecture note: config.ts loaded at module import time",
      "issue": "The PRD allows “TTL-based invalidation implemented with atomic swap semantics” but does not constrain what can be safely hot-reloaded. Given config.ts is imported at module load, many call sites will have captured config values in closures/constants; a TTL refresh can create split-brain behavior within a single process unless all consumers read through an indirection.",
      "why_blocking": "A partial hot-reload can cause inconsistent enforcement (e.g., boundary mode toggles, limits, keys) across requests in the same instance, which is dangerous for economic invariants and auth. This can manifest as intermittent production failures that are extremely hard to debug.",
      "fix": "Constrain TTL-based invalidation to a clearly defined subset of config keys that are read dynamically through a single accessor (e.g., getConfig()). Require an audit of call sites or enforce via lint/type pattern. Otherwise, choose cold-restart as the only supported strategy in this cycle and explicitly mark TTL refresh as out of scope."
    }
  ],
  "question": "",
  "iteration": 1
}
