{
  "verdict": "CHANGES_REQUIRED",
  "summary": "The overall approach is implementable, but several specified mechanisms (supply-chain verification, determinism, import access control, and boundary replay) as written will not reliably work and can cause either security failure or a blocked rollout.",
  "blocking_issues": [
    {
      "location": "3.2 FR-2: Rebuild Script Update (Supply-chain verification)",
      "issue": "The script verifies only the git commit SHA of a cloned repo and then runs `require('@0xhoneyjar/loa-hounfour...')` from the current workspace, which does not prove the built dist artifacts correspond to the verified SHA (TOCTOU / wrong-artifact verification).",
      "why_blocking": "This can pass verification while consuming a different artifact (e.g., cached node_modules, a different install source, or a tampered package), violating the PRD security requirement and creating a supply-chain gap that can ship compromised code.",
      "fix": "Bind verification to the exact artifact you will publish/consume: (1) build in an isolated temp dir, (2) compute and record a content hash of the produced dist (or pack tarball) and verify it in CI, and (3) run the export-resolution checks against that built output (e.g., `node -e \"require('./dist/core')\"` or `node --conditions=...` with explicit path), not against whatever happens to be installed in node_modules. If the dependency is installed via git SHA in package.json, also verify the installed package’s `gitHead`/embedded version metadata (or vendor a `SOURCE_SHA` file into dist during build) and assert it equals EXPECTED_SHA."
    },
    {
      "location": "3.2 FR-2: Rebuild Script Update (Determinism claim)",
      "issue": "Adding `tsc --strict` does not make builds deterministic; `--strict` is a type-checking mode, not a reproducibility control, and may not even apply if the project uses a tsconfig with different settings.",
      "why_blocking": "The SDD claims deterministic builds as a mitigation (NFR / security posture). This will not achieve the stated property and can lead to non-reproducible artifacts across environments, undermining the supply-chain verification story and causing CI/prod drift.",
      "fix": "Define actual determinism controls: pin Node + TypeScript versions (e.g., via `.nvmrc`/Volta + `devDependencies`), use `npm ci`/`pnpm --frozen-lockfile`, ensure `tsconfig` has stable settings (`declaration`, `sourceMap` policy, `newLine`, `importsNotUsedAsValues`, etc.), and (if needed) set `SOURCE_DATE_EPOCH` and avoid embedding timestamps. Update the script to use the repo’s `node_modules/.bin/tsc -p tsconfig.json` and fail if lockfile is not honored."
    },
    {
      "location": "2.2 Import Access Control (Enforcement)",
      "issue": "The proposed ESLint rule `import/no-restricted-paths` is the wrong mechanism for restricting package specifier imports like `@0xhoneyjar/loa-hounfour` and will not reliably prevent direct canonical imports outside the allowlist.",
      "why_blocking": "PRD requires import access control enforcement. If enforcement is ineffective, consumers can bypass the adapter/barrel, causing type divergence, boundary parsing bypass (FR-6), and inconsistent runtime behavior—exactly the regression risk this cycle is trying to eliminate.",
      "fix": "Use an enforcement that matches module specifiers: `no-restricted-imports` (ESLint core) with patterns for `@0xhoneyjar/loa-hounfour*`, plus an override allowlist for the permitted globs. Alternatively enforce via TypeScript project references + path mapping (only barrel exposed) or a CI check that parses import specifiers (AST-based) rather than grep."
    },
    {
      "location": "3.1 FR-1: Boundary payload replay (AC-1.6)",
      "issue": "The design asserts comparing parsed output between v7.0.0 and v7.9.2, but the repo will only have one version installed at a time; the SDD does not specify how both versions are loaded/executed in the same test run.",
      "why_blocking": "This test as described is not implementable without a dual-install strategy; it will block Phase 1/2 validation or devolve into a no-op comparison against the same version, missing regressions.",
      "fix": "Specify a concrete dual-version harness: install v7.0.0 under an alias (e.g., `@0xhoneyjar/loa-hounfour-v7_0_0` via npm alias or a second git dependency) and import both in the replay test, or run the replay test twice in CI (matrix) and compare serialized golden outputs committed to the repo. Define the exact fixtures and the canonical serialization format for comparison."
    },
    {
      "location": "3.3 FR-3: Protocol barrel expansion (TypeScript correctness / export surface)",
      "issue": "Several barrel exports are asserted to come from `@0xhoneyjar/loa-hounfour` root when other parts of the SDD imply subpath exports (`/economy`, `/integrity`, etc.). If the package uses export maps, importing from the wrong specifier will fail at runtime even if types compile (or vice versa).",
      "why_blocking": "A mismatched export map will cause runtime module resolution failures in Node (especially under ESM/exports), breaking the app and tests immediately after the pin bump.",
      "fix": "Validate each re-export against the actual v7.9.2 `package.json#exports` map and align specifiers accordingly (root vs subpath). Add an automated export-map validation test that imports every barrel re-exported symbol from the exact specifier used (not just `require('@0xhoneyjar/loa-hounfour/subpath')`). If the project is ESM, use dynamic `import()` rather than `require()`."
    },
    {
      "location": "3.6 FR-6: parseMicroUsd boundary adoption (Dual-parse operational safety)",
      "issue": "The wrapper returns legacy values when canonical rejects but legacy accepts, meaning the system continues to accept inputs the new boundary intends to forbid; combined with logging-only, this can prevent ever reaching a safe cutover and can mask active abuse at boundaries.",
      "why_blocking": "PRD/NFR requires boundary tightening with safe transition. As written, you may never enforce the stricter boundary (attackers can keep sending rejected-by-canonical inputs), and you also risk inconsistent behavior across services depending on env var state.",
      "fix": "Make the rollout explicitly staged with measurable gates: (1) shadow mode logs only but still rejects obviously dangerous classes (e.g., whitespace/plus/leading zeros) behind a separate flag, or (2) return a discriminated union from the wrapper (`{ok:true,value}` / `{ok:false,reason}`) and force callers to decide; then implement a progressive enforcement flag (`PARSE_MICRO_USD_ENFORCE=true`) that flips canonical rejection into a hard 400/validation error at HTTP/JWT boundaries while keeping DB/Redis readers tolerant with normalization. Also define a metric + threshold and a timeboxed plan to remove legacy fallback."
    }
  ],
  "question": null,
  "iteration": 1
}
