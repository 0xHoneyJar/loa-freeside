{
  "verdict": "CHANGES_REQUIRED",
  "summary": "The overall doc architecture is implementable, but several specified validation/generation mechanisms will not work reliably as written and would prevent meeting PRD truth-grounding and automation gates.",
  "blocking_issues": [
    {
      "location": "3.2 BUTTERFREEZONE.md — Canonicalization architecture (deterministic array ordering, trim strings)",
      "issue": "Canonicalization rules are underspecified/unsafe: “deterministic array ordering” and “trim string values” can change semantics and are not well-defined, making hashes unstable or incorrect across runs.",
      "why_blocking": "FR-2/NFR-2 require a trustworthy, agent-readable, integrity-verifiable artifact. If canonicalization is ambiguous (what arrays are sortable? by which key? what about arrays where order is meaningful?) or mutates content (trimming strings), the same source can hash differently across environments/versions, or worse, different sources can hash the same. This breaks the acceptance gate and undermines the integrity guarantee.",
      "fix": "Define a strict JSON Canonicalization Scheme (e.g., RFC 8785 JCS) and explicitly prohibit semantic mutations. Do not trim strings. Only sort object keys; never reorder arrays unless the extractor emits arrays in a deterministic order by construction (e.g., sort extracted route entries by {method,path,source} before emitting). Document exact normalization (UTF-8, newline handling, number formatting) and implement it in a single library/script used by both gen and validate."
    },
    {
      "location": "3.2 Golden test vectors + butterfreezone-validate.sh",
      "issue": "Golden vectors are described as “input.md → expected.json/hash”, but the generator is described as scanning the codebase, not transforming Markdown sections; the validation approach is internally inconsistent and likely unimplementable as stated.",
      "why_blocking": "FR-2 requires golden vectors that test the extraction/canonicalization logic. If the extraction operates on codebase structures (TS files, package.json, routes), a fixture of “input.md” doesn’t exercise the real extractor. Teams will either skip the gate or implement a different pipeline than documented, failing the cycle’s core requirement.",
      "fix": "Align fixtures with the real extractor: create fixture directories that mimic minimal repo structure (package.json + a few TS route/command/interface files) and run the extractor against that fixture tree. Store expected canonical JSON per section and expected hashes. Alternatively, if you truly want Markdown-section extraction, change the generator to be Markdown-driven and specify the section grammar—pick one and make gen/validate share the same inputs."
    },
    {
      "location": "3.5 docs/API-REFERENCE.md — extract-routes approach (grep router.(get|post|...))",
      "issue": "Route extraction via grep on `router.get(` patterns will miss common Express patterns (router.use with sub-routers, exported routers composed elsewhere, dynamic paths, method chaining, variables/constants), producing an incomplete or misleading route index.",
      "why_blocking": "FR-4 requires a route index for the remaining 70+ endpoints. If the index is incomplete, external developers will hit undocumented endpoints or assume endpoints don’t exist; the “auto-extracted” claim becomes false, and the RTFM validation can’t reliably assert completeness.",
      "fix": "Implement extraction using AST parsing (TypeScript compiler API / ts-morph) over the routes directory to detect Router method calls, router.use mounts, and path constants. Resolve mounted base paths to produce full paths. At minimum, add a hard gate: compare extracted count to a known baseline (or to runtime route table if available) and fail CI if it drops unexpectedly."
    },
    {
      "location": "4.1 Tooling Pipeline vs 9.1 RTFM Validation — pin-citations.sh and “source:” citations",
      "issue": "The citation model is split between HTML comments (`<!-- source: ... -->`) and a separate `repo@version:path` syntax for pinning, but RTFM validation only mentions `source:` citations. This mismatch will cause the pinning/validation automation to miss citations or fail to pin them.",
      "why_blocking": "NFR-1 requires truth-grounded docs with cross-repo citation rules and an actual pinning script. If the system can’t reliably detect and rewrite citations, you’ll ship branch-relative or unpinned references, violating the PRD and breaking long-term doc integrity.",
      "fix": "Standardize on one machine-readable citation syntax across all docs (including README comments), e.g. `<!-- cite: owner/repo@<ref>:path#Lx-Ly -->` or a YAML/JSON block. Update both `pin-citations.sh` and RTFM checks to parse exactly that syntax. Ensure the pinning script can resolve local paths and remote repos to commit SHAs and rewrite to permalinks consistently."
    },
    {
      "location": "3.4 docs/API-QUICKSTART.md + 9.2 Smoke-Test Protocol",
      "issue": "Smoke tests for JWT-required endpoints assume a valid `$JWT` exists, but the SDD does not specify how developers obtain/generate a JWT in local dev (issuer, signing keys, JWKS hosting, audience), making the validation step non-executable.",
      "why_blocking": "FR-4 requires copy-pastable curl examples and a smoke-test checklist that validates docs against a running instance. If auth cannot be reproduced deterministically, the smoke-test gate will fail or be skipped, and the docs won’t be verifiably accurate.",
      "fix": "Add an explicit local-auth setup section: how to generate a dev keypair, where to configure the server to trust it, how to mint a JWT (command/script), required claims (`iss`,`aud`,`exp`,`sub`), and a one-liner to export `$JWT`. If the platform supports an auth-bypass in dev, document it with strong warnings and ensure it’s disabled by default."
    },
    {
      "location": "3.3 docs/ECOSYSTEM.md — ecosystem-stats.sh (remote repos via gh api “latest release tag stats or cached values”)",
      "issue": "The stats plan relies on data that GitHub APIs don’t provide directly (e.g., “lines” and “tests” for a release) unless you clone and run tools; “cached values” are undefined, making the script non-implementable as specified.",
      "why_blocking": "FR-3 requires a 5-repo ecosystem map with stats and a generation script. If the script can’t actually compute the stats for remote repos, you can’t meet the requirement or will ship fabricated/hand-entered numbers, violating truth-grounding.",
      "fix": "Choose an implementable method: (a) shallow-clone each repo at a pinned ref and run `cloc` + test discovery locally in CI, or (b) require each repo to publish a machine-readable `repo-stats.json` artifact in releases that your script fetches. Define exactly what “tests count” means and how it’s computed."
    }
  ],
  "question": null,
  "iteration": 1
}
