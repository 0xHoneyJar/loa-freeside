{
  "verdict": "CHANGES_REQUIRED",
  "summary": "The migration can work, but as written it has two failure-class risks: (1) backward-compat normalization that can silently weaken authz/version gating, and (2) drift/rollback mechanisms that won’t reliably prevent or recover from unintended protocol changes at this scale.",
  "blocking_issues": [
    {
      "location": "3.7 Coordination Schema (FR-6) + 3.4.2 arrakis-compat.ts normalizeCoordinationMessage()",
      "issue": "Design explicitly says: “No version field → assume v4.6.0 (legacy)”. This creates a version-downgrade ambiguity and makes the normalizer a bypass surface for any v7-only required fields/semantics.",
      "why_blocking": "In a mixed-version environment, accepting unversioned messages as legacy allows an attacker/buggy peer to omit version to force the looser parsing path. If v7 introduces stricter invariants (fields, signatures, replay semantics, trust scopes, coordination structure), the legacy path can accept messages that should be rejected, causing authz or billing/conservation enforcement gaps across the service boundary.",
      "fix": "Require an explicit version discriminator for all inbound coordination messages once arrakis is on v7 (even during transition). If you must support truly legacy senders, gate it by: (a) authenticated peer identity allowlist, (b) endpoint separation (e.g., /compat/v4 vs /compat/v7), or (c) a signed header/claim that includes contract_version. At minimum: treat missing version as an error unless the sender is positively identified as legacy and the message passes a strict v4 schema validator."
    },
    {
      "location": "3.6 Breaking Change: trust_scopes (FR-5) + 6.1 JWT Boundary + arrakis-compat.ts normalizeInboundClaims()",
      "issue": "Inbound accepts either v4 trust_level or v7 trust_scopes, but the SDD does not define a safe, monotonic mapping from trust_level → trust_scopes, nor does it state precedence/consistency rules when both are present.",
      "why_blocking": "This is an authz boundary. If mapping is permissive or ambiguous (e.g., trust_level=9 maps to admin/write/read without verifying issuer intent), a v4 token could be normalized into broader scopes than intended. If both fields are present, an attacker could craft conflicting claims and rely on whichever branch the normalizer chooses. Either case can lead to privilege escalation (admin/write) and downstream economic actions (billing/reservations) being authorized incorrectly.",
      "fix": "Define an explicit, least-privilege mapping table (trust_level → scopes) with documented invariants (e.g., monotone, no admin unless explicitly allowed). Enforce: (1) exactly one of {trust_level, trust_scopes} accepted; if both present, reject. (2) issuer/audience/subject constraints unchanged and validated before normalization. (3) normalization outputs a canonical claim object that is re-validated against the v7 schema post-normalization. Add negative tests for conflicting fields and for boundary values (min/max trust_level)."
    },
    {
      "location": "3.5 Conservation Dual-Run Validation (FR-3)",
      "issue": "Dual-run compares “pass/fail on all 14 invariants”, but canonical v7 is described as having “147 constraints”. The harness as specified can miss semantic regressions where v7 adds constraints or changes invariant granularity; it also allows “ENUMERATED_DIFFS” to permanently mask real safety changes without a formal acceptance criterion.",
      "why_blocking": "Billing correctness is the trust anchor. If v7 tightens invariants (likely, given 147 constraints), a pass/fail comparison against a v4 snapshot can either (a) fail constantly and get papered over via ENUMERATED_DIFFS, or (b) only compare a subset (14) and miss new failure modes. Either outcome can ship with conservation leakage or false rejects that break production billing flows.",
      "fix": "Make the comparison target explicit and complete: either (A) compare canonical v7 evaluator against an independently specified set of conservation laws (preferred), or (B) compare full canonical result structure (including invariant IDs) and require: v7 must be >= v4 strictness on a defined subset, and any additional v7 failures must be triaged with a bounded, time-limited allowlist that expires. Also add targeted generators for edge cases (overflow bounds, negative/zero microUSD, terminal transitions) and require coverage of all canonical invariant IDs at least once across the property corpus."
    },
    {
      "location": "3.8 CI Drift Detection (FR-7) + dependency spec in 3.1",
      "issue": "Drift detection relies on parsing package-lock.json for a GitHub commit SHA substring in “resolved”. This is not stable across npm versions/lockfile formats and can silently stop working; additionally, the dependency is pinned to a Git tag, which can be force-moved in GitHub repos.",
      "why_blocking": "If drift detection is flaky or bypassable, arrakis can unknowingly consume a different protocol commit than reviewed, breaking cross-service contracts or conservation invariants. At this scale (40+ consumers), a silent protocol drift is a project-failure class event because it invalidates the whole “1:1 replacement” guarantee and can cause production incompatibility with loa-finn.",
      "fix": "Pin immutably and verify immutably: use a commit SHA in the dependency spec (github:org/repo#<sha>) or a published package version with integrity. In CI, verify via: (1) import CONTRACT_VERSION, (2) read the installed package’s own package.json version + gitHead (if present), and/or (3) verify npm’s integrity field (package-lock v2 has integrity). Avoid substring matching on resolved URLs."
    },
    {
      "location": "8 Rollback Strategy",
      "issue": "Rollback assumes a single squash merge + git revert is sufficient, but the change touches 40+ direct imports and deletes vendored files. Reverting may not restore the exact previous dependency graph if the lockfile and transitive deps changed, and “restore vendored files from git history” is not a complete rollback if other commits landed after the squash.",
      "why_blocking": "If production breaks (auth boundary, billing invariants, coordination parsing), you need a deterministic rollback. A revert that leaves the lockfile or transitive resolution altered can keep the system in a broken mixed state. Given the scope, a non-deterministic rollback is a real outage risk.",
      "fix": "Define a deterministic rollback artifact: tag the pre-migration commit and keep a release branch; ensure the revert includes package-lock.json and any generated artifacts. Prefer a feature-flag style dual-run in production for the boundary normalizers (v4/v7) so you can disable v7 parsing without code rollback. At minimum, document an exact rollback PR that restores: dependency spec, lockfile, vendored protocol directory, and consumer import paths (scripted)."
    }
  ],
  "question": null,
  "iteration": 1
}
