{
  "verdict": "CHANGES_REQUIRED",
  "summary": "Core direction is workable, but several database/migration and RLS/authz gaps will cause production outages or cross-tenant data exposure, and the event-sourcing/governance models have correctness holes that will break replay and policy enforcement under concurrency.",
  "blocking_issues": [
    {
      "location": "3.2.1 Migration 0012: ALTER TABLE lot_entries ADD COLUMN purpose ... NOT NULL DEFAULT 'unclassified'",
      "issue": "This is not guaranteed to be non-blocking/online on a large hot table; it can still take an ACCESS EXCLUSIVE lock and/or create long lock waits during the catalog change, and the new DEFAULT/NOT NULL semantics can create unexpected write amplification during peak traffic depending on tooling and statement timeout.",
      "why_blocking": "If lot_entries is large and continuously written, a blocking ALTER can stall all ledger writes (debits/credits/reserves), effectively halting the economic system. The SDD claims “zero downtime” without a safe phased approach.",
      "fix": "Use a phased, truly online pattern: (1) ADD COLUMN purpose economic_purpose NULL (no default), (2) backfill in small batches (UPDATE ... WHERE purpose IS NULL LIMIT ... via id ranges), (3) ADD DEFAULT 'unclassified' (metadata-only), (4) VALIDATE with CHECK constraint first (ADD CONSTRAINT purpose_not_null CHECK (purpose IS NOT NULL) NOT VALID; then VALIDATE CONSTRAINT), (5) only then SET NOT NULL in a maintenance window if required—or keep CHECK constraint as enforcement. Ensure Drizzle migration uses separate statements and sets lock_timeout/statement_timeout appropriately."
    },
    {
      "location": "3.2.3 Migration 0014: idx_active_policies partial index uses NOW() in predicate",
      "issue": "PostgreSQL does not allow non-immutable functions like NOW() in index predicates; this index DDL will fail at migration time.",
      "why_blocking": "Migration failure blocks deployment; governance feature cannot ship and may block other migrations if run as a batch.",
      "fix": "Remove NOW() from the predicate. Model “active” via state + effective_until column comparisons at query time, or add a derived boolean column (e.g., is_effective) maintained by application/sweep and index that. Example: partial index WHERE state='active' AND superseded_by IS NULL; then filter effective_until in query."
    },
    {
      "location": "3.2.4 Migration 0015: admin_audit_log trigger references prevent_mutation() which is not defined in this SDD",
      "issue": "Migration references a missing function; DDL will fail.",
      "why_blocking": "Deployment/migration failure. Also undermines SKP-007 admin audit trail requirement if immutability isn’t actually enforced.",
      "fix": "Define prevent_mutation() in this SDD/migration set (or reuse an existing function explicitly by name/path). Ensure it blocks UPDATE/DELETE and is installed before the trigger. Also consider REVOKE UPDATE/DELETE at role level for defense-in-depth."
    },
    {
      "location": "3.2.2 Migration 0013: correlation_id UUID NOT NULL DEFAULT gen_random_uuid() on lot_entries",
      "issue": "gen_random_uuid() requires pgcrypto; SDD doesn’t assert extension presence. Also adding NOT NULL with default on a hot table is presented as rewrite-free; the extension dependency and migration tool behavior can still break production rollout.",
      "why_blocking": "If pgcrypto isn’t enabled in prod, migration fails. If migration tool wraps statements in a transaction, CREATE INDEX CONCURRENTLY will fail (cannot run inside a transaction block), causing partial migration and broken deploy.",
      "fix": "Explicitly include `CREATE EXTENSION IF NOT EXISTS pgcrypto;` (or switch to uuid-ossp and uuid_generate_v4 with extension). Also specify migration execution constraints: Drizzle must run 0013 with `transaction: false` (or split into separate migrations) so CONCURRENTLY indexes are executed outside a transaction."
    },
    {
      "location": "3.2.2 Migration 0013: CREATE VIEW community_operations groups by correlation_id, community_id, entry_type, purpose",
      "issue": "This view is not correlation-aware in the way SKP-002 requires: a single economic operation can include multiple purposes (or mixed entry types) and multi-lot splits; grouping by purpose and entry_type fragments the operation and can double-count or misrepresent operation totals.",
      "why_blocking": "Downstream aggregation (velocity, governance audit, reporting) will be wrong, and replay/consistency checks that rely on operation grouping will be inconsistent. This is a correctness failure, not a cosmetic issue.",
      "fix": "Define a canonical operation model: group strictly by (community_id, correlation_id) and compute per-operation rollups with structured breakdowns (e.g., JSONB aggregates by purpose/entry_type) or provide two views: (1) operations header (one row per correlation_id) and (2) operation_lines (per purpose/entry_type). Also specify correlation_id propagation rules: all postings created by one logical operation MUST share the same correlation_id across lots and entry types."
    },
    {
      "location": "5.3 Event Sourcing Service: replayState() switch logic for debit/reserve/release/expire",
      "issue": "Replay semantics are inconsistent with a double-entry append-only ledger and will drift: (a) debit increases total_committed_micro but reserve/release do not affect committed; (b) expire subtracts the lot’s current balance regardless of whether prior debits already reduced it, which can double-subtract depending on how expire is represented in lot_entries; (c) governance events insert lot_id NULL but replay assumes event.lot_id exists for most types.",
      "why_blocking": "verifyConsistency will frequently report drift or, worse, produce incorrect reconstructed state. This breaks the event-sourcing feature and any governance/audit that depends on replay correctness.",
      "fix": "Define the canonical posting model precisely: for each entry_type, specify which accounts/aggregates change and whether amount_micro is signed/unsigned. Ensure expire is represented as explicit postings (e.g., debit remaining balance to an expiry sink) rather than “subtract current lot balance” during replay. Enforce NOT NULL lot_id for economic entry types at DB level (CHECK constraint) and handle governance as a separate event table or a dedicated nullable-safe branch with schema constraints."
    },
    {
      "location": "5.4 Governance approve(): BigInt conversion from JSON policy_value.limit_micro",
      "issue": "BigInt(policy.policy_value.limit_micro) will throw if limit_micro is a JSON number (not a string) or exceeds JS safe integer when parsed by the driver; also policy_value is JSONB and returned as an object—type ambiguity can break approvals in production.",
      "why_blocking": "Governance approvals will intermittently fail depending on how clients send JSON and how pg driver deserializes JSONB. This blocks policy lifecycle and can deadlock communities in pending enforcement.",
      "fix": "Require limit_micro to be stored and transported as a string everywhere (API schema + DB constraint). Add validation: zod refine that limit_micro is a decimal string representing a non-negative integer within BigInt range. Consider storing policy_value fields that are monetary as TEXT columns (limit_micro_text) to avoid JSON numeric ambiguity."
    },
    {
      "location": "1.9 / 5.5 RLS enforcement completeness (SKP-007): withCommunityScope only sets app.community_id; policies use current_setting('app.community_id') without missing_ok; admin_audit_log has no RLS",
      "issue": "RLS can be bypassed or cause unsafe failures: (a) any query path that forgets withCommunityScope will error or, worse, run without tenant filter if a table lacks RLS; (b) current_setting('app.community_id') without `missing_ok=true` throws, turning some bugs into outages; (c) admin_audit_log has no RLS and no explicit privilege model described—any DB role used by the app could read all audit logs cross-tenant.",
      "why_blocking": "This is a cross-tenant data exposure risk and/or an availability risk. SKP-007 requires enforcement across ALL code paths; the SDD doesn’t define DB role privileges and relies on middleware discipline.",
      "fix": "Harden at the DB layer: (1) use `current_setting('app.community_id', true)` in policies and add a policy clause that denies when NULL; (2) enable RLS on all tenant tables and REVOKE BYPASSRLS from app roles; (3) ensure the app DB role has no SELECT on admin_audit_log unless explicitly needed, or add RLS + separate privileged role for platform audit access; (4) add automated tests that scan adapters for any pool.query usage not wrapped by withCommunityScope and fail CI."
    },
    {
      "location": "3.2.2 Migration 0013 + 5.3 allocateSequence(): sequencing contention mitigation (SKP-003) is not actually specified beyond flags",
      "issue": "Tiered contention mitigation is asserted but not designed: advisory locks and pre-allocated ranges are mentioned without concrete algorithm, failure modes, or correctness guarantees (especially under retries/rollbacks).",
      "why_blocking": "Under the stated upper bound (≤50 concurrent ops/community), SELECT FOR UPDATE may be fine, but without a real Tier 2/3 design you risk hitting a hard ceiling and having no safe upgrade path. If you flip SEQUENCE_LOCK_MODE without a specified algorithm, you can create duplicate or skipped sequences that break replay ordering assumptions.",
      "fix": "Specify exact Tier 2 and Tier 3 mechanisms: Tier 2: pg_advisory_xact_lock(hash(community_id)) + UPDATE ... RETURNING next_sequence in one statement. Tier 3: allocate ranges by atomically incrementing next_sequence by N and returning [start,end], store range in-process with lease/expiry; define behavior on crash (ranges may be skipped but never duplicated) and require replay consumers tolerate gaps (IMP-002). Include SQL for atomic increment: `UPDATE community_event_sequences SET next_sequence = next_sequence + $N WHERE community_id=$1 RETURNING next_sequence - $N AS start;`."
    },
    {
      "location": "4.x API + 5.4 Governance: communityId in path vs actor.community_id; missing explicit cross-check",
      "issue": "Endpoints accept :communityId but middleware/handlers don’t explicitly enforce actor.community_id === req.params.communityId before withCommunityScope. If resolveActor returns a community_id and a caller supplies a different path id, you can get confusing authorization behavior and potential data leakage depending on how withCommunityScope is invoked.",
      "why_blocking": "This is a classic multi-tenant bug class. Even if RLS blocks some reads, writes can fail unpredictably or leak metadata via timing/errors; it also violates SKP-007’s “across ALL code paths” intent.",
      "fix": "Add a mandatory guard in routing middleware: reject if actor.community_id !== params.communityId unless actor.role is platform-admin with explicit audited override. Ensure withCommunityScope always uses params.communityId after this check (or always uses actor.community_id and ignore the path)."
    }
  ],
  "question": "",
  "iteration": 1
}
