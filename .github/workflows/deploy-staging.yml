# =============================================================================
# Staging Deployment Workflow (Cycle 044 — Multi-Service)
# =============================================================================
# Builds and deploys freeside (API + Worker) and dixie to AWS ECS Staging.
#
# Pipeline order per SDD §11.1:
#   1. Build + push Docker images
#   2. Terraform plan + apply (if infra changes)
#   3. Run migrations (HARD GATE — both must exit 0)
#   4. Deploy services (API + Worker + Dixie in parallel)
#   5. Wait for stability
#   6. Smoke test (staging-smoke.sh)
#
# Triggers:
#   - Push to staging branch (auto-deploy)
#   - Manual workflow dispatch
#
# Required Secrets:
#   - AWS_ACCESS_KEY_ID
#   - AWS_SECRET_ACCESS_KEY
# =============================================================================

name: Deploy to Staging

# SKP-004: Prevent parallel pipeline runs from racing migrations
concurrency:
  group: deploy-staging
  cancel-in-progress: false

on:
  push:
    branches:
      - staging
    paths:
      - 'themes/sietch/**'
      - 'packages/**'
      - 'infrastructure/**'
      - '.github/workflows/deploy-staging.yml'
  workflow_dispatch:
    inputs:
      image_tag:
        description: 'Image tag to deploy'
        required: false
        default: 'staging'
      skip_migrations:
        description: 'Skip migration tasks (use for hotfix deploys)'
        required: false
        default: 'false'

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: arrakis-staging-api
  ECR_DIXIE_REPOSITORY: arrakis-staging-dixie
  ECR_BASE_REPOSITORY: arrakis-base
  ECS_CLUSTER: arrakis-staging-cluster
  ECS_SERVICE_API: arrakis-staging-api
  ECS_SERVICE_WORKER: arrakis-staging-worker
  ECS_SERVICE_DIXIE: arrakis-staging-dixie

jobs:
  # ===========================================================================
  # Build and Push
  # ===========================================================================
  # NOTE: Database migrations must be run manually via ECS Exec before first deploy
  # The RDS is in a private VPC and not accessible from GitHub Actions runners.
  # Run: aws ecs execute-command --cluster arrakis-staging-cluster --task <task-id> \
  #      --container api --interactive --command "psql $DATABASE_URL -f drizzle/migrations/0005_eligibility_tables.sql"
  build:
    name: Build & Push to ECR
    runs-on: ubuntu-latest

    outputs:
      image_tag: ${{ steps.meta.outputs.tags }}
      image_sha: ${{ steps.build.outputs.digest }}
      short_sha: ${{ steps.vars.outputs.short_sha }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set variables
        id: vars
        run: |
          echo "short_sha=$(echo ${{ github.sha }} | cut -c1-7)" >> $GITHUB_OUTPUT

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}
          tags: |
            type=sha,prefix=
            type=raw,value=staging
            type=raw,value=${{ github.event.inputs.image_tag || 'staging' }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          # Build from repo root to include @arrakis/adapters dependency
          context: .
          file: ./themes/sietch/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            GIT_SHA=${{ github.sha }}

      - name: Output image details
        run: |
          echo "### Docker Image Built (Staging) :whale:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Repository:** \`${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Tags:** \`${{ steps.meta.outputs.tags }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Digest:** \`${{ steps.build.outputs.digest }}\`" >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # Run Migrations (HARD GATE — SDD §5.2, §11.1)
  # ===========================================================================
  # Both migrations must exit 0 before any service container is deployed.
  # Advisory lock prevents concurrent execution. IMP-004 timeout semantics.
  run-migrations:
    name: Run Database Migrations
    runs-on: ubuntu-latest
    needs: build
    if: ${{ github.event.inputs.skip_migrations != 'true' }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run freeside migration
        run: |
          echo "Running freeside migration (drizzle-kit push)..."
          TASK_ARN=$(aws ecs run-task \
            --cluster ${{ env.ECS_CLUSTER }} \
            --task-definition arrakis-staging-freeside-migration \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE_API }} --query 'services[0].networkConfiguration.awsvpcConfiguration.subnets' --output text | tr '\t' ','),securityGroups=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE_API }} --query 'services[0].networkConfiguration.awsvpcConfiguration.securityGroups' --output text | tr '\t' ','),assignPublicIp=DISABLED}" \
            --query 'tasks[0].taskArn' \
            --output text)

          echo "Migration task: $TASK_ARN"
          echo "Waiting for completion (timeout: 120s)..."

          aws ecs wait tasks-stopped --cluster ${{ env.ECS_CLUSTER }} --tasks "$TASK_ARN"

          EXIT_CODE=$(aws ecs describe-tasks \
            --cluster ${{ env.ECS_CLUSTER }} \
            --tasks "$TASK_ARN" \
            --query 'tasks[0].containers[0].exitCode' \
            --output text)

          if [ "$EXIT_CODE" != "0" ]; then
            echo "MIGRATION FAILED: freeside migration exited with code $EXIT_CODE"
            echo "Check CloudWatch logs for details"
            exit 1
          fi
          echo "Freeside migration completed successfully"

      - name: Run dixie migration
        run: |
          echo "Running dixie migration (node dist/db/migrate.js)..."
          TASK_ARN=$(aws ecs run-task \
            --cluster ${{ env.ECS_CLUSTER }} \
            --task-definition arrakis-staging-dixie-migration \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE_API }} --query 'services[0].networkConfiguration.awsvpcConfiguration.subnets' --output text | tr '\t' ','),securityGroups=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE_API }} --query 'services[0].networkConfiguration.awsvpcConfiguration.securityGroups' --output text | tr '\t' ','),assignPublicIp=DISABLED}" \
            --query 'tasks[0].taskArn' \
            --output text)

          echo "Migration task: $TASK_ARN"
          echo "Waiting for completion (timeout: 120s)..."

          aws ecs wait tasks-stopped --cluster ${{ env.ECS_CLUSTER }} --tasks "$TASK_ARN"

          EXIT_CODE=$(aws ecs describe-tasks \
            --cluster ${{ env.ECS_CLUSTER }} \
            --tasks "$TASK_ARN" \
            --query 'tasks[0].containers[0].exitCode' \
            --output text)

          if [ "$EXIT_CODE" != "0" ]; then
            echo "MIGRATION FAILED: dixie migration exited with code $EXIT_CODE"
            echo "Check CloudWatch logs for details"
            exit 1
          fi
          echo "Dixie migration completed successfully"

  # ===========================================================================
  # Deploy API Service (parallel with Worker + Dixie, after migrations)
  # ===========================================================================
  deploy-api:
    name: Deploy API Service
    runs-on: ubuntu-latest
    needs: [build, run-migrations]
    if: ${{ !cancelled() && needs.build.result == 'success' && (needs.run-migrations.result == 'success' || needs.run-migrations.result == 'skipped') }}

    outputs:
      task_definition_arn: ${{ steps.update.outputs.task_definition_arn }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Get and update API task definition
        id: update
        run: |
          # Get current task definition
          aws ecs describe-task-definition \
            --task-definition arrakis-staging-api \
            --query 'taskDefinition' \
            --output json > task-definition.json

          # Clean task definition for registration
          jq 'del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)' \
            task-definition.json > task-definition-clean.json

          # Update image
          NEW_IMAGE="${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ needs.build.outputs.short_sha }}"
          echo "Updating API task definition with image: $NEW_IMAGE"

          jq --arg IMAGE "$NEW_IMAGE" \
            '.containerDefinitions[0].image = $IMAGE' \
            task-definition-clean.json > task-definition-new.json

          # Register new task definition
          NEW_TASK_DEF_ARN=$(aws ecs register-task-definition \
            --cli-input-json file://task-definition-new.json \
            --query 'taskDefinition.taskDefinitionArn' \
            --output text)

          echo "New API task definition: $NEW_TASK_DEF_ARN"
          echo "task_definition_arn=$NEW_TASK_DEF_ARN" >> $GITHUB_OUTPUT

      - name: Update ECS API Service
        run: |
          aws ecs update-service \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service ${{ env.ECS_SERVICE_API }} \
            --task-definition ${{ steps.update.outputs.task_definition_arn }} \
            --force-new-deployment \
            --query 'service.deployments[0].{status:status,running:runningCount,desired:desiredCount}' \
            --output table

  # ===========================================================================
  # Deploy Worker Service (parallel with API + Dixie, after migrations)
  # ===========================================================================
  deploy-worker:
    name: Deploy Worker Service
    runs-on: ubuntu-latest
    needs: [build, run-migrations]
    if: ${{ !cancelled() && needs.build.result == 'success' && (needs.run-migrations.result == 'success' || needs.run-migrations.result == 'skipped') }}

    outputs:
      task_definition_arn: ${{ steps.update.outputs.task_definition_arn }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Get and update Worker task definition
        id: update
        run: |
          # Get current task definition
          aws ecs describe-task-definition \
            --task-definition arrakis-staging-worker \
            --query 'taskDefinition' \
            --output json > task-definition.json

          # Clean task definition for registration
          jq 'del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)' \
            task-definition.json > task-definition-clean.json

          # Update image
          NEW_IMAGE="${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ needs.build.outputs.short_sha }}"
          echo "Updating Worker task definition with image: $NEW_IMAGE"

          jq --arg IMAGE "$NEW_IMAGE" \
            '.containerDefinitions[0].image = $IMAGE' \
            task-definition-clean.json > task-definition-new.json

          # Register new task definition
          NEW_TASK_DEF_ARN=$(aws ecs register-task-definition \
            --cli-input-json file://task-definition-new.json \
            --query 'taskDefinition.taskDefinitionArn' \
            --output text)

          echo "New Worker task definition: $NEW_TASK_DEF_ARN"
          echo "task_definition_arn=$NEW_TASK_DEF_ARN" >> $GITHUB_OUTPUT

      - name: Update ECS Worker Service
        run: |
          aws ecs update-service \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service ${{ env.ECS_SERVICE_WORKER }} \
            --task-definition ${{ steps.update.outputs.task_definition_arn }} \
            --force-new-deployment \
            --query 'service.deployments[0].{status:status,running:runningCount,desired:desiredCount}' \
            --output table

  # ===========================================================================
  # Deploy Dixie Service (parallel with API + Worker, after migrations)
  # ===========================================================================
  deploy-dixie:
    name: Deploy Dixie Service
    runs-on: ubuntu-latest
    needs: [build, run-migrations]
    if: ${{ !cancelled() && needs.build.result == 'success' && (needs.run-migrations.result == 'success' || needs.run-migrations.result == 'skipped') }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Get and update Dixie task definition
        id: update
        run: |
          # Get current task definition
          aws ecs describe-task-definition \
            --task-definition arrakis-staging-dixie \
            --query 'taskDefinition' \
            --output json > task-definition.json

          # Clean task definition for registration
          jq 'del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)' \
            task-definition.json > task-definition-clean.json

          # Update image with git SHA tag (IMP-003)
          NEW_IMAGE="${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_DIXIE_REPOSITORY }}:${{ needs.build.outputs.short_sha }}"
          echo "Updating Dixie task definition with image: $NEW_IMAGE"

          jq --arg IMAGE "$NEW_IMAGE" \
            '.containerDefinitions[0].image = $IMAGE' \
            task-definition-clean.json > task-definition-new.json

          # Register new task definition
          NEW_TASK_DEF_ARN=$(aws ecs register-task-definition \
            --cli-input-json file://task-definition-new.json \
            --query 'taskDefinition.taskDefinitionArn' \
            --output text)

          echo "New Dixie task definition: $NEW_TASK_DEF_ARN"
          echo "task_definition_arn=$NEW_TASK_DEF_ARN" >> $GITHUB_OUTPUT

      - name: Update ECS Dixie Service
        run: |
          aws ecs update-service \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service ${{ env.ECS_SERVICE_DIXIE }} \
            --task-definition ${{ steps.update.outputs.task_definition_arn }} \
            --force-new-deployment \
            --query 'service.deployments[0].{status:status,running:runningCount,desired:desiredCount}' \
            --output table

  # ===========================================================================
  # Wait for All Services (combined wait)
  # ===========================================================================
  verify-deployment:
    name: Verify Deployment
    runs-on: ubuntu-latest
    needs: [deploy-api, deploy-worker, deploy-dixie]

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Wait for services stability (parallel)
        run: |
          echo "Waiting for all services to stabilize..."

          aws ecs wait services-stable \
            --cluster ${{ env.ECS_CLUSTER }} \
            --services ${{ env.ECS_SERVICE_API }} &
          API_PID=$!

          aws ecs wait services-stable \
            --cluster ${{ env.ECS_CLUSTER }} \
            --services ${{ env.ECS_SERVICE_WORKER }} &
          WORKER_PID=$!

          aws ecs wait services-stable \
            --cluster ${{ env.ECS_CLUSTER }} \
            --services ${{ env.ECS_SERVICE_DIXIE }} &
          DIXIE_PID=$!

          wait $API_PID;   API_STATUS=$?
          wait $WORKER_PID; WORKER_STATUS=$?
          wait $DIXIE_PID;  DIXIE_STATUS=$?

          if [ $API_STATUS -eq 0 ] && [ $WORKER_STATUS -eq 0 ] && [ $DIXIE_STATUS -eq 0 ]; then
            echo "All services are stable!"
          else
            echo "Service stability check failed (api=$API_STATUS worker=$WORKER_STATUS dixie=$DIXIE_STATUS)"
            exit 1
          fi

      - name: Deployment Summary
        run: |
          echo "### Staging Deployment Complete :rocket:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          for svc in ${{ env.ECS_SERVICE_API }} ${{ env.ECS_SERVICE_WORKER }} ${{ env.ECS_SERVICE_DIXIE }}; do
            STATUS=$(aws ecs describe-services \
              --cluster ${{ env.ECS_CLUSTER }} \
              --services "$svc" \
              --query 'services[0].{Running:runningCount,Desired:desiredCount}' \
              --output json)
            echo "**$svc:** $STATUS" >> $GITHUB_STEP_SUMMARY
          done

  # ===========================================================================
  # Smoke Test (SDD §10.1 — replaces simple health check)
  # ===========================================================================
  smoke-test:
    name: Staging Smoke Test
    runs-on: ubuntu-latest
    needs: verify-deployment

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Install dependencies
        run: npm ci --ignore-scripts

      - name: Run staging smoke test
        env:
          FREESIDE_URL: https://staging.api.arrakis.community
          DIXIE_URL: https://dixie.staging.arrakis.community
        run: |
          chmod +x scripts/staging-smoke.sh
          ./scripts/staging-smoke.sh --json 2>smoke-results.json

      - name: Upload smoke test results
        if: always()
        run: |
          if [ -f smoke-results.json ]; then
            echo "### Smoke Test Results :test_tube:" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            cat smoke-results.json >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
